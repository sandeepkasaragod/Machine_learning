{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66cefc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple deep learning script for predicting the breast cancer. \n",
    "# Data can be found at \"https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "68f6d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ee7742cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will encode the text to number\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2cc41f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data using pandas\n",
    "df = pd.read_csv(\"data.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f5388b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the \"ID\" column. We don't need this in the prediction\n",
    "df = df.drop(\"id\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "96083742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the category column to number\n",
    "df['diagnosis'] = encoder.fit_transform(df['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "147cace6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display the header\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6dc312fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the processed data to a file\n",
    "df.to_csv(\"preprocessed.csv\", sep=\",\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "31bbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the processed data using numpy (very flexible )\n",
    "df = np.loadtxt(\"preprocessed.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ec56ba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the features\n",
    "X = df[:,1:31]\n",
    "\n",
    "#set the label (diagnosis)\n",
    "y= df[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d0eabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the layer\n",
    "model = Sequential()\n",
    "model.add(Dense(34, input_dim=30, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f03421a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba517156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "36/36 [==============================] - 1s 7ms/step - loss: 12.1694 - accuracy: 0.6011 - val_loss: 1.2022 - val_accuracy: 0.7181\n",
      "Epoch 2/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.8699 - val_loss: 0.4927 - val_accuracy: 0.8670\n",
      "Epoch 3/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8910 - val_loss: 0.2699 - val_accuracy: 0.9202\n",
      "Epoch 4/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8963 - val_loss: 0.2618 - val_accuracy: 0.9202\n",
      "Epoch 5/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3306 - accuracy: 0.8998 - val_loss: 0.2534 - val_accuracy: 0.9202\n",
      "Epoch 6/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3730 - accuracy: 0.8875 - val_loss: 0.2510 - val_accuracy: 0.9362\n",
      "Epoch 7/150\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8998 - val_loss: 0.3677 - val_accuracy: 0.8883\n",
      "Epoch 8/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.9121 - val_loss: 0.6263 - val_accuracy: 0.8245\n",
      "Epoch 9/150\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.9192 - val_loss: 0.3824 - val_accuracy: 0.8830\n",
      "Epoch 10/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.9086 - val_loss: 0.2515 - val_accuracy: 0.9202\n",
      "Epoch 11/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2413 - accuracy: 0.9209 - val_loss: 0.3581 - val_accuracy: 0.8883\n",
      "Epoch 12/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8822 - val_loss: 0.4772 - val_accuracy: 0.8830\n",
      "Epoch 13/150\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8822 - val_loss: 0.2704 - val_accuracy: 0.9149\n",
      "Epoch 14/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.9139 - val_loss: 0.2884 - val_accuracy: 0.9096\n",
      "Epoch 15/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8910 - val_loss: 0.5690 - val_accuracy: 0.8351\n",
      "Epoch 16/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8928 - val_loss: 0.2473 - val_accuracy: 0.9362\n",
      "Epoch 17/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8752 - val_loss: 0.2326 - val_accuracy: 0.9362\n",
      "Epoch 18/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.9016 - val_loss: 0.2245 - val_accuracy: 0.9255\n",
      "Epoch 19/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.9139 - val_loss: 0.2667 - val_accuracy: 0.9149\n",
      "Epoch 20/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.9174 - val_loss: 0.6440 - val_accuracy: 0.8777\n",
      "Epoch 21/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2988 - accuracy: 0.9051 - val_loss: 0.2229 - val_accuracy: 0.9309\n",
      "Epoch 22/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.9121 - val_loss: 0.6565 - val_accuracy: 0.8085\n",
      "Epoch 23/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2740 - accuracy: 0.9051 - val_loss: 0.2425 - val_accuracy: 0.9202\n",
      "Epoch 24/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2659 - accuracy: 0.9104 - val_loss: 0.1990 - val_accuracy: 0.9362\n",
      "Epoch 25/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2404 - accuracy: 0.9192 - val_loss: 0.2040 - val_accuracy: 0.9362\n",
      "Epoch 26/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.9209 - val_loss: 0.2435 - val_accuracy: 0.9149\n",
      "Epoch 27/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2285 - accuracy: 0.9156 - val_loss: 0.4884 - val_accuracy: 0.8404\n",
      "Epoch 28/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8752 - val_loss: 0.2208 - val_accuracy: 0.9149\n",
      "Epoch 29/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.9051 - val_loss: 0.3482 - val_accuracy: 0.8883\n",
      "Epoch 30/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2176 - accuracy: 0.9297 - val_loss: 0.2724 - val_accuracy: 0.9202\n",
      "Epoch 31/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.9244 - val_loss: 0.7113 - val_accuracy: 0.7766\n",
      "Epoch 32/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2581 - accuracy: 0.9209 - val_loss: 0.2169 - val_accuracy: 0.9255\n",
      "Epoch 33/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.9174 - val_loss: 0.2669 - val_accuracy: 0.9255\n",
      "Epoch 34/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.9192 - val_loss: 0.1822 - val_accuracy: 0.9362\n",
      "Epoch 35/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2331 - accuracy: 0.9279 - val_loss: 0.2173 - val_accuracy: 0.9202\n",
      "Epoch 36/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2165 - accuracy: 0.9262 - val_loss: 0.1692 - val_accuracy: 0.9521\n",
      "Epoch 37/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2231 - accuracy: 0.9262 - val_loss: 0.2375 - val_accuracy: 0.9255\n",
      "Epoch 38/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9156 - val_loss: 0.1934 - val_accuracy: 0.9309\n",
      "Epoch 39/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9244 - val_loss: 0.4614 - val_accuracy: 0.8351\n",
      "Epoch 40/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2043 - accuracy: 0.9297 - val_loss: 0.2576 - val_accuracy: 0.9149\n",
      "Epoch 41/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2375 - accuracy: 0.9139 - val_loss: 0.1711 - val_accuracy: 0.9309\n",
      "Epoch 42/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2433 - accuracy: 0.9174 - val_loss: 0.1612 - val_accuracy: 0.9521\n",
      "Epoch 43/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9192 - val_loss: 0.2625 - val_accuracy: 0.9149\n",
      "Epoch 44/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.9139 - val_loss: 0.1969 - val_accuracy: 0.9202\n",
      "Epoch 45/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.8418 - val_loss: 0.3589 - val_accuracy: 0.8936\n",
      "Epoch 46/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2806 - accuracy: 0.9069 - val_loss: 0.2455 - val_accuracy: 0.9255\n",
      "Epoch 47/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2099 - accuracy: 0.9315 - val_loss: 0.1662 - val_accuracy: 0.9521\n",
      "Epoch 48/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2022 - accuracy: 0.9332 - val_loss: 0.1635 - val_accuracy: 0.9415\n",
      "Epoch 49/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9279 - val_loss: 0.1637 - val_accuracy: 0.9468\n",
      "Epoch 50/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2356 - accuracy: 0.9104 - val_loss: 0.3173 - val_accuracy: 0.8989\n",
      "Epoch 51/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9104 - val_loss: 0.1654 - val_accuracy: 0.9521\n",
      "Epoch 52/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9315 - val_loss: 0.1664 - val_accuracy: 0.9362\n",
      "Epoch 53/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9209 - val_loss: 0.1884 - val_accuracy: 0.9415\n",
      "Epoch 54/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9156 - val_loss: 0.1706 - val_accuracy: 0.9415\n",
      "Epoch 55/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8805 - val_loss: 0.7952 - val_accuracy: 0.8670\n",
      "Epoch 56/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.8612 - val_loss: 0.1720 - val_accuracy: 0.9362\n",
      "Epoch 57/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2279 - accuracy: 0.9209 - val_loss: 0.1746 - val_accuracy: 0.9521\n",
      "Epoch 58/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9156 - val_loss: 0.1682 - val_accuracy: 0.9468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.9104 - val_loss: 0.3565 - val_accuracy: 0.8989\n",
      "Epoch 60/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.9016 - val_loss: 0.3606 - val_accuracy: 0.8989\n",
      "Epoch 61/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8981 - val_loss: 0.3020 - val_accuracy: 0.9149\n",
      "Epoch 62/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9227 - val_loss: 0.1870 - val_accuracy: 0.9415\n",
      "Epoch 63/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9244 - val_loss: 0.1509 - val_accuracy: 0.9521\n",
      "Epoch 64/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2303 - accuracy: 0.9227 - val_loss: 0.1585 - val_accuracy: 0.9468\n",
      "Epoch 65/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1945 - accuracy: 0.9279 - val_loss: 0.2883 - val_accuracy: 0.9202\n",
      "Epoch 66/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9385 - val_loss: 0.1468 - val_accuracy: 0.9574\n",
      "Epoch 67/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9297 - val_loss: 0.1538 - val_accuracy: 0.9468\n",
      "Epoch 68/150\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.2227 - accuracy: 0.9209 - val_loss: 0.2533 - val_accuracy: 0.9255\n",
      "Epoch 69/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1884 - accuracy: 0.9385 - val_loss: 0.1416 - val_accuracy: 0.9521\n",
      "Epoch 70/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9385 - val_loss: 0.1461 - val_accuracy: 0.9415\n",
      "Epoch 71/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9315 - val_loss: 0.1968 - val_accuracy: 0.9202\n",
      "Epoch 72/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.9385 - val_loss: 0.1520 - val_accuracy: 0.9415\n",
      "Epoch 73/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.9473 - val_loss: 0.1417 - val_accuracy: 0.9415\n",
      "Epoch 74/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1660 - accuracy: 0.9350 - val_loss: 0.2290 - val_accuracy: 0.9202\n",
      "Epoch 75/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1703 - accuracy: 0.9332 - val_loss: 0.1713 - val_accuracy: 0.9362\n",
      "Epoch 76/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.9051 - val_loss: 0.1335 - val_accuracy: 0.9521\n",
      "Epoch 77/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2479 - accuracy: 0.9279 - val_loss: 0.2758 - val_accuracy: 0.9149\n",
      "Epoch 78/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.9279 - val_loss: 0.1388 - val_accuracy: 0.9468\n",
      "Epoch 79/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9121 - val_loss: 0.1420 - val_accuracy: 0.9521\n",
      "Epoch 80/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9315 - val_loss: 0.2861 - val_accuracy: 0.9096\n",
      "Epoch 81/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9438 - val_loss: 0.1885 - val_accuracy: 0.9202\n",
      "Epoch 82/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9332 - val_loss: 0.1941 - val_accuracy: 0.9202\n",
      "Epoch 83/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9420 - val_loss: 0.1466 - val_accuracy: 0.9309\n",
      "Epoch 84/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.9174 - val_loss: 0.4415 - val_accuracy: 0.8883\n",
      "Epoch 85/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8946 - val_loss: 0.1882 - val_accuracy: 0.9202\n",
      "Epoch 86/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9350 - val_loss: 0.2004 - val_accuracy: 0.9309\n",
      "Epoch 87/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1728 - accuracy: 0.9385 - val_loss: 0.1522 - val_accuracy: 0.9415\n",
      "Epoch 88/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9174 - val_loss: 0.1314 - val_accuracy: 0.9468\n",
      "Epoch 89/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9420 - val_loss: 0.1539 - val_accuracy: 0.9362\n",
      "Epoch 90/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9350 - val_loss: 0.1434 - val_accuracy: 0.9468\n",
      "Epoch 91/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1765 - accuracy: 0.9473 - val_loss: 0.1478 - val_accuracy: 0.9362\n",
      "Epoch 92/150\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1611 - accuracy: 0.9315 - val_loss: 0.1529 - val_accuracy: 0.9415\n",
      "Epoch 93/150\n",
      "36/36 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9279 - val_loss: 0.1330 - val_accuracy: 0.9521\n",
      "Epoch 94/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1560 - accuracy: 0.9438 - val_loss: 0.1421 - val_accuracy: 0.9521\n",
      "Epoch 95/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.9350 - val_loss: 0.1292 - val_accuracy: 0.9521\n",
      "Epoch 96/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1530 - accuracy: 0.9525 - val_loss: 0.1853 - val_accuracy: 0.9255\n",
      "Epoch 97/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9473 - val_loss: 0.1961 - val_accuracy: 0.9309\n",
      "Epoch 98/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9279 - val_loss: 0.1274 - val_accuracy: 0.9468\n",
      "Epoch 99/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9297 - val_loss: 0.2022 - val_accuracy: 0.9255\n",
      "Epoch 100/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9473 - val_loss: 0.3881 - val_accuracy: 0.8777\n",
      "Epoch 101/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9332 - val_loss: 0.2408 - val_accuracy: 0.9255\n",
      "Epoch 102/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1808 - accuracy: 0.9350 - val_loss: 0.2614 - val_accuracy: 0.9202\n",
      "Epoch 103/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.9244 - val_loss: 0.3299 - val_accuracy: 0.8989\n",
      "Epoch 104/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9315 - val_loss: 0.1403 - val_accuracy: 0.9521\n",
      "Epoch 105/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9473 - val_loss: 0.4132 - val_accuracy: 0.8936\n",
      "Epoch 106/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9332 - val_loss: 0.3867 - val_accuracy: 0.8883\n",
      "Epoch 107/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.9174 - val_loss: 0.2086 - val_accuracy: 0.9309\n",
      "Epoch 108/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.9086 - val_loss: 0.4700 - val_accuracy: 0.8883\n",
      "Epoch 109/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2942 - accuracy: 0.8981 - val_loss: 0.1784 - val_accuracy: 0.9255\n",
      "Epoch 110/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.9104 - val_loss: 0.1384 - val_accuracy: 0.9468\n",
      "Epoch 111/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2036 - accuracy: 0.9262 - val_loss: 0.1681 - val_accuracy: 0.9309\n",
      "Epoch 112/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9420 - val_loss: 0.1630 - val_accuracy: 0.9362\n",
      "Epoch 113/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9438 - val_loss: 0.2004 - val_accuracy: 0.9202\n",
      "Epoch 114/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9279 - val_loss: 0.1239 - val_accuracy: 0.9415\n",
      "Epoch 115/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.9033 - val_loss: 0.1548 - val_accuracy: 0.9362\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9473 - val_loss: 0.1634 - val_accuracy: 0.9362\n",
      "Epoch 117/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1462 - accuracy: 0.9402 - val_loss: 0.1329 - val_accuracy: 0.9362\n",
      "Epoch 118/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2980 - accuracy: 0.9051 - val_loss: 0.3751 - val_accuracy: 0.8989\n",
      "Epoch 119/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9332 - val_loss: 0.2294 - val_accuracy: 0.9362\n",
      "Epoch 120/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9174 - val_loss: 0.1401 - val_accuracy: 0.9415\n",
      "Epoch 121/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2024 - accuracy: 0.9227 - val_loss: 0.1700 - val_accuracy: 0.9309\n",
      "Epoch 122/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9385 - val_loss: 0.1378 - val_accuracy: 0.9362\n",
      "Epoch 123/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9350 - val_loss: 0.1318 - val_accuracy: 0.9415\n",
      "Epoch 124/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1392 - accuracy: 0.9490 - val_loss: 0.1197 - val_accuracy: 0.9574\n",
      "Epoch 125/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1671 - accuracy: 0.9420 - val_loss: 0.1604 - val_accuracy: 0.9362\n",
      "Epoch 126/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9420 - val_loss: 0.1272 - val_accuracy: 0.9415\n",
      "Epoch 127/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9508 - val_loss: 0.1261 - val_accuracy: 0.9415\n",
      "Epoch 128/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9367 - val_loss: 0.1207 - val_accuracy: 0.9415\n",
      "Epoch 129/150\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.2239 - accuracy: 0.9139 - val_loss: 0.1760 - val_accuracy: 0.9309\n",
      "Epoch 130/150\n",
      "20/36 [===============>..............] - ETA: 0s - loss: 0.1956 - accuracy: 0.9312"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, validation_data=(X_test,y_test), epochs=150, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af4f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
